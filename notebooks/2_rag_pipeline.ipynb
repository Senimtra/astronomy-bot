{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Model\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "\n",
    "# Embeddings Model\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-large')\n",
    "\n",
    "# Chroma DB Vector Store\n",
    "vector_store = Chroma(persist_directory = '../chroma_db', embedding_function = embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM short-circuit prompt\n",
    "\n",
    "prompt_short_circuit = (\n",
    "    \"If the query contains factual questions, retrieve documents.\"\n",
    "    \"You **must always call the `nasa` tool** to fetch relevant NASA images.\"\n",
    "    \"If you call the `nasa` tool, you must also call the `podcast` tool to initialize.\"\n",
    "    \"If the query is conversation, respond immediately.\"\n",
    "    \"You love astronomy and to engage with curious kids!\"\n",
    "    \"Keep your response short, and fun (five sentences max).\"\n",
    "    \"Add single relevant emojies within the text.\"\n",
    "    \"Always make sure to end the response with an emoji.\"\n",
    "    \"\\n\\n\"\n",
    "    \"When using the 'nasa' tool, provide only a single word as input.\"\n",
    "    \"This word should represent the main object of the query.\"\n",
    "    \"Such as the singular name of a celestial body or astronomical object.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval step prompt\n",
    "\n",
    "prompt_retrieval = (\n",
    "    \"You're a friendly and enthusiastic astronomy teacher who loves explaining space facts to curious kids!\"\n",
    "    \"Use the following pieces of context to answer the question at the end in a fun, simple, and engaging way.\"\n",
    "    \"Keep your explanation short, fun, and easy to understand (five sentences max).\"\n",
    "    \"Use playful language, examples, or comparisons to make the answer exciting for kids.\"\n",
    "    \"Always end with an encouraging phrase like ´Keep looking up!´ or ´Space is awesome, isn't it?´ to keep them excited about learning.\"\n",
    "    \"Add single relevant emojies within the text. Always make sure to end the response with a single emoji\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store retrieval step tool\n",
    "\n",
    "@tool(response_format = 'content')\n",
    "def vector_db(query: str):\n",
    "    \"\"\"Retrieve astronomical information chunks from chromaDB\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k = 2)\n",
    "    serialized = '\\n\\n'.join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASA Images retrieval step tool\n",
    "\n",
    "last_search = None\n",
    "\n",
    "@tool(response_format = 'content')\n",
    "def nasa_images(search_word: str):\n",
    "    \"\"\"Fetch relevant space images from NASA Images Api\"\"\"\n",
    "    global last_search\n",
    "    if search_word != last_search:\n",
    "        BASE_URL = 'https://images-api.nasa.gov/search'\n",
    "        params = {\n",
    "            'q': search_word,\n",
    "            'media_type': 'image',\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params = params)\n",
    "        data = response.json()\n",
    "        items = data.get('collection').get('items')\n",
    "        # Get the first 8 image objects\n",
    "        images = [item.get('links') for item in items[:8]]\n",
    "        # Get the image links\n",
    "        image_links = [image[0]['href'] for image in images]\n",
    "        # Update last search string\n",
    "        last_search = search_word\n",
    "\n",
    "        return image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podcast initialization step tool\n",
    "\n",
    "podcast_setup = {\n",
    "    'topic': None,\n",
    "    'llm': 'gpt-4o-mini',\n",
    "    'queries': []\n",
    "}\n",
    "\n",
    "@tool(response_format = 'content')\n",
    "def podcast(search_word:str, query: str):\n",
    "    \"\"\"Initialize podcast\"\"\"\n",
    "    # Update podcast (new topic)\n",
    "    if search_word != podcast_setup['topic']:\n",
    "        podcast_setup['topic'] = search_word\n",
    "        podcast_setup['queries'] = [query]\n",
    "    # Update podcast (add message)\n",
    "    else:\n",
    "        podcast_setup['queries'].append(query)\n",
    "\n",
    "    return podcast_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE 1: LLM decides to retrieve documents or respond immediately\n",
    "\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tools call for retrieval or respond\"\"\"\n",
    "    system_message_content = prompt_short_circuit\n",
    "    system_message = SystemMessage(system_message_content)\n",
    "    llm_with_tools = llm.bind_tools([vector_db, nasa_images, podcast])\n",
    "    # Appends messages to MessagesState\n",
    "    response = llm_with_tools.invoke([system_message] + state['messages'])\n",
    "    # Return updated MessagesState\n",
    "    return {'messages': [response]}\n",
    "\n",
    "\n",
    "# NODE 2: Registers and executes retrieval if needed\n",
    "\n",
    "tools = ToolNode([vector_db, nasa_images, podcast])\n",
    "\n",
    "\n",
    "# NODE 3: Generate retrieval response\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer based on retrieved data\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state['messages']):\n",
    "        if message.type == 'tool':\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    # Restore chronological order\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into retrieval prompt\n",
    "    docs_content = '\\n\\n'.join(doc.content for doc in tool_messages)\n",
    "    system_message_content = f\"{prompt_retrieval}\\n\\n{docs_content}\"\n",
    "\n",
    "    conversation_history = [\n",
    "        message for message in state['messages']\n",
    "        if message.type in ('human', 'system')\n",
    "        # Exclude AI tool call messages\n",
    "        or (message.type == 'ai' and not message.tool_calls)\n",
    "    ]\n",
    "\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_history\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Graph\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add Nodes\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "# Define entry point\n",
    "graph_builder.set_entry_point('query_or_respond')\n",
    "\n",
    "# Define dynamic flow\n",
    "graph_builder.add_conditional_edges(\n",
    "    'query_or_respond',\n",
    "    tools_condition,\n",
    "    {END: END, 'tools': 'tools'}\n",
    ")\n",
    "\n",
    "# Define fixed transitions\n",
    "graph_builder.add_edge('tools', 'generate')\n",
    "graph_builder.add_edge('generate', END)\n",
    "\n",
    "# Simple in-memory checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the Graph\n",
    "graph = graph_builder.compile(checkpointer = memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control flow visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set session thread_id\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "\n",
    "def message_test(input_message):\n",
    "    \"\"\"DRY message test function\"\"\"\n",
    "    for step in graph.stream(\n",
    "        {'messages': [{'role': 'user', 'content': input_message}]},\n",
    "        stream_mode = 'values',\n",
    "        config = config\n",
    "    ):\n",
    "        step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational message - LLM short-circuit - NO Images (conversation)\n",
    "\n",
    "message_test(input_message = 'Hello. I do have a question about the universe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astronomy question - RETRIEVAL step - FETCH Images\n",
    "\n",
    "message_test(input_message = 'How hot is it on the sun?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astronomy question (memory usage) - RETRIEVAL step - NO Images (same topic)\n",
    "\n",
    "message_test(input_message = 'Is it big?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astronomy question (memory usage) - LLM short-circuit - NO Images (shortcut)\n",
    "\n",
    "message_test(input_message = 'Would I be able to live on it?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astronomy question - RETRIEVAL step (back from short-circuit) - FETCH Images\n",
    "\n",
    "message_test(input_message = 'How about brown dwars? Are they real?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-Context question - LLM short-circuit - NO Images (no context)\n",
    "\n",
    "message_test(input_message = 'Do you know OpenAI?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational message - LLM short-circuit - NO Images (conversation)\n",
    "\n",
    "message_test(input_message = 'Thank you. Have a nice day!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
